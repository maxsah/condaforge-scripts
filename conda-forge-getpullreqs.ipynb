{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "The below statements import all the relevant libraries that are used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, datetime\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from github import Github\n",
    "from getpass import getpass\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feedstocks!\n",
    "\n",
    "conda-forge calls the github repositories used to connect the original python packages to a conda package. Check out this page if you'd like to see what's in them: https://conda-forge.org/feedstocks/\n",
    "We will later iterate over these pages so we can check out the pull requests (PRs) in them.\n",
    "\n",
    "A status code of 200 means it was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage with all packages\n",
    "r = requests.get('https://conda-forge.org/feedstocks/')\n",
    "\n",
    "# check the status code returned\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse out what we need from the feedstocks\n",
    "\n",
    "BeautifulSoup is a great web scraping package used. In this case we use it to convert the response from `requests` into something pythonic\n",
    "\n",
    "As you can see it grabs the links and shows you the first three feedstocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the response to get package names\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "table = soup.find(\"section\", {\"id\": \"feedstocks\"})\n",
    "links = [a['href'] for a in table.findAll('a')]\n",
    "\n",
    "# inspect the links\n",
    "links[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writetoresults\n",
    "\n",
    "This function will come up in a minute. It's how we write the pull requests to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writetoresults(pullrecs,writefile):\n",
    "    #this is where we use pandas (note the 'pd' below). It's really only because I'm lazy\n",
    "    #and it's a simple way to quickly write to a CSV. \n",
    "    pullrecs_df=pd.DataFrame(pullrecs,columns=['package name','pull request title'])\n",
    "    pullrecs_df.to_csv(writefile,mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate!\n",
    "\n",
    "In order to parse through the git pages, we are now going to use the Github python package to request the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input should be pretty self explanatory. it allows the user to type\n",
    "# in their username into a prompt\n",
    "username=input('enter your github username')\n",
    "\n",
    "# in order to keep the password private, using the getpass package allows for\n",
    "# the password to be not stored in the code and also appear as dots. \n",
    "password=getpass('input password')\n",
    "\n",
    "g=Github(username,password)\n",
    "writefile=input('file output path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getpullrecs\n",
    "\n",
    "The meat of the script. Iterates over the `links` variable, determines if there are PRs, and if they are there they add them to the `pullrecs` variable. \n",
    "\n",
    "Each time it has iterated over 100 packages (counted by the `j` variable), it calls the writetoresults() function, which allows for incremental writing to a CSV in case the process is interrupted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpullrecs():\n",
    "    j=0\n",
    "    pullrecs=[]\n",
    "    linktest=links[:5] \n",
    "    # trange is part of the tqdm package. it's what makes the progress bar when you run this\n",
    "    with trange(len(links)) as t:\n",
    "        # iterating this way over the trange is how the % on the progress bar updates \n",
    "        for i in t:\n",
    "            tries=1\n",
    "            # in case there is a failure with a request, we don't want the function to fail\n",
    "            # instead it tries each package 10 times before it gives up and the function fails\n",
    "            while tries < 10:\n",
    "                try:\n",
    "                    link=links[i][19:]\n",
    "                    # t is the trange we set with the above with statement. this changes the\n",
    "                    # description as it iterates.\n",
    "                    t.set_description('the current package is: {}'.format(link[12:]))\n",
    "                    r=g.get_repo(link)\n",
    "                    pulls = r.get_pulls(state='open', sort='created', base='master')\n",
    "                    if pulls.totalCount>0:\n",
    "                        for pull in pulls:\n",
    "                            pullrecs.append((r.name,pull.title))\n",
    "                    break\n",
    "                except:\n",
    "                    # this needs to get updated to handle the specific exception. \n",
    "                    # this is here because Github doesn't allow infinite requests over and over again\n",
    "                    # effectively, you can only make so many requests before they tell you to knock it off\n",
    "                    # which is after 5000 attempts in 60 minutes (and right now we are making roughly\n",
    "                    # 12000 calls). once you hit that limit, you have to pause for an hour before starting\n",
    "                    # to make more requests, otherwise they may blackball your account or IP. \n",
    "                    print('rate limited @ {}'.format(str(datetime.datetime.now())))\n",
    "                    time.sleep(3630)\n",
    "            j+=1\n",
    "            if j==100:\n",
    "                # see? when j==100, write to results!\n",
    "                writetoresults(pullrecs,writefile)\n",
    "                pullrecs=[]\n",
    "                # and reset the counter\n",
    "                j=0\n",
    "\n",
    "    # since we probably don't end on a number divisible by 100, once we fall out of the \n",
    "    # loop we need to write the rest of those results. \n",
    "    writetoresults(pullrecs,writefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getpullrecs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
